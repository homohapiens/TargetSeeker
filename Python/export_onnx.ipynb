{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['obs_0', 'obs_1']\n",
      "['version_number', 'memory_size', 'continuous_actions', 'continuous_action_output_shape']\n",
      "{'obs_0': {0: 'batch'}, 'obs_1': {0: 'batch'}, 'continuous_actions': {0: 'batch'}, 'continuous_action_output_shape': {0: 'batch'}}\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "import torch\n",
    "from torch.nn import Parameter\n",
    "import gym\n",
    "\n",
    "class OnnxablePolicy(torch.nn.Module):\n",
    "    def __init__(self, policy, output_sizes: list):\n",
    "        super(OnnxablePolicy, self).__init__()\n",
    "        self.extractor = policy.mlp_extractor\n",
    "        self.action_net = policy.action_net\n",
    "        self.value_net = policy.value_net\n",
    "\n",
    "        version_number = torch.tensor([3], dtype=torch.float32, device='cpu')\n",
    "        self.version_number = Parameter(version_number, requires_grad=False)\n",
    "        memory_size = torch.tensor([0], dtype=torch.float32, device='cpu')\n",
    "        self.memory_size = Parameter(memory_size, requires_grad=False)\n",
    "\n",
    "        action_out_shape = torch.tensor([output_sizes[0]], dtype=torch.float32, device='cpu')\n",
    "        self.action_out_shape = Parameter(action_out_shape, requires_grad=False)\n",
    "\n",
    "    def forward(self, observation0, observation1):\n",
    "        # NOTE: You may have to process (normalize) observation in the correct\n",
    "        #       way before using this. See `common.preprocessing.preprocess_obs`\n",
    "        observation = torch.concat((observation0, observation1), dim=1)\n",
    "        action_hidden, value_hidden = self.extractor(observation)\n",
    "\n",
    "        action_out = self.action_net(action_hidden)\n",
    "        value_out = self.value_net(value_hidden)\n",
    "        \n",
    "        return self.version_number, self.memory_size, action_out, self.action_out_shape\n",
    "\n",
    "\n",
    "# Example: model = PPO(\"MlpPolicy\", \"Pendulum-v1\")\n",
    "model = PPO.load('TargetSeeker.zip')\n",
    "model.policy.to(\"cpu\")\n",
    "input_sizes=[85, 12]\n",
    "output_sizes=[3]\n",
    "onnxable_model = OnnxablePolicy(model.policy, output_sizes)\n",
    "\n",
    "# Input names\n",
    "input_names=['obs_0', 'obs_1']\n",
    "\n",
    "# Output names\n",
    "output_names = ['version_number', 'memory_size']\n",
    "if isinstance(model.policy.action_space, gym.spaces.Discrete):\n",
    "    output_names += ['discrete_actions']\n",
    "    output_names += ['discrete_action_output_shape']\n",
    "if isinstance(model.policy.action_space, gym.spaces.Box):\n",
    "    output_names += ['continuous_actions']\n",
    "    output_names += ['continuous_action_output_shape']\n",
    "\n",
    "# Dynamic axes\n",
    "dynamic_axes={}\n",
    "for name in input_names+output_names[-2:]:\n",
    "    dynamic_axes[name] = {0: 'batch'}\n",
    "\n",
    "print(f'{input_names}\\n{output_names}\\n{dynamic_axes}')\n",
    "\n",
    "# Export the model to ONNX\n",
    "dummy_input = tuple(torch.randn(1, x) for x in input_sizes)\n",
    "torch.onnx.export(\n",
    "    onnxable_model,\n",
    "    dummy_input, \n",
    "    'TargetSeeker.onnx',\n",
    "    opset_version=9, \n",
    "    input_names=input_names,\n",
    "    output_names=output_names,\n",
    "    dynamic_axes=dynamic_axes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test exported model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['obs_0', 'obs_1']\n",
      "['version_number', 'memory_size', 'continuous_actions', 'continuous_action_output_shape']\n",
      "[array([3.], dtype=float32), array([0.], dtype=float32), array([[ 0.09262253,  0.02039998, -0.03820657]], dtype=float32), array([3.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "##### Load and test with onnx\n",
    "\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "onnx_path = 'TargetSeeker.onnx'\n",
    "onnx_model = onnx.load(onnx_path)\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "print([x.name for x in onnx_model.graph.input])\n",
    "print([x.name for x in onnx_model.graph.output])\n",
    "\n",
    "observation0 = np.zeros((1, 85)).astype(np.float32)\n",
    "observation1 = np.zeros((1, 12)).astype(np.float32)\n",
    "ort_sess = ort.InferenceSession(onnx_path)\n",
    "out = ort_sess.run(None, {'obs_0': observation0, 'obs_1': observation1})\n",
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mla-gym)",
   "language": "python",
   "name": "mla-gym"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
